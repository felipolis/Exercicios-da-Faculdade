ZooKeeper: Wait-free coordination for Internet-scale systems

Resumo
Neste artigo, descrevemos o ZooKeeper, um serviço para coordenação de processos de aplicações distribuídas. Como o ZooKeeper faz parte da infraestrutura crítica, o ZooKeeper visa fornecer um kernel simples e de alto desempenho para a construção de primitivas de coordenação mais complexas no cliente. Ele incorpora elementos de mensagens de grupo, registros compartilhados e serviços de bloqueio distribuído em um serviço replicado e centralizado. A interface exposta pelo Zoo-Keeper tem os aspectos sem espera de registros compartilhados com um mecanismo orientado a eventos semelhante a invalidações de cache de sistemas de arquivos distribuídos para fornecer um serviço de coordenação simples, mas poderoso.

A interface do ZooKeeper permite uma implementação de serviço de alto desempenho. Além da propriedade sem espera, o ZooKeeper fornece uma garantia por cliente de execução FIFO de solicitações e capacidade de linearização para todas as solicitações que alteram o estado do ZooKeeper. Essas decisões de design permitem a implementação de um pipeline de processamento de alto desempenho com solicitações de leitura atendidas por servidores locais. Mostramos para as cargas de trabalho de destino, taxa de leitura para gravação de 2:1 a 100:1, que o ZooKeeper pode lidar com centenas de milhares de transações por segundo. Esse desempenho permite que o ZooKeeper seja usado extensivamente por aplicativos clientes.


1. Introdução
Aplicações distribuídas em larga escala requerem diferentes formas de coordenação. A configuração é uma das formas mais básicas de coordenação. Em sua forma mais simples, a configuração é apenas uma lista de parâmetros operacionais para os processos do sistema, enquanto sistemas mais sofisticados possuem parâmetros de configuração dinâmicos. A participação em grupos e a eleição de líderes também são comuns em sistemas distribuídos: frequentemente, os processos precisam saber quais outros processos estão ativos e pelo que esses processos são responsáveis. Os bloqueios constituem uma primitiva de coordenação poderosa que implementa acesso mutuamente exclusivo a recursos críticos.

Uma abordagem para a coordenação é desenvolver serviços para cada uma das diferentes necessidades de coordenação. Por exemplo, Amazon Simple Queue Service [3] enfoca especificamente o enfileiramento. Outros serviços foram desenvolvidos especificamente para eleição de líderes [25] e configuração [27]. Os serviços que implementam primitivos mais poderosos podem ser usados para implementar os menos poderosos. Por exemplo, Chubby [6] é um serviço de bloqueio com fortes garantias de sincronização. Os bloqueios podem então ser usados para implementar a eleição de líder, associação de grupo, etc.

Ao projetar nosso serviço de coordenação, deixamos de implementar primitivas específicas no lado do servidor e, em vez disso, optamos por expor uma API que permite aos desenvolvedores de aplicativos implementar suas próprias primitivas. Tal escolha levou à implementação de um kernel de coordenação que permite novas primitivas sem exigir mudanças no núcleo de serviço. Essa abordagem permite múltiplas formas de coordenação adaptadas aos requisitos das aplicações, ao invés de restringir os desenvolvedores a um conjunto fixo de primitivas.

Ao projetar a API do ZooKeeper, nos afastamos dos primitivos de bloqueio, como bloqueios. Blockingprimitives para um serviço de coordenação pode causar, entre outros problemas, clientes lentos ou defeituosos impactando negativamente o desempenho de clientes mais rápidos. A implementação do serviço em si torna-se mais complicada se o processamento de pedidos depender de respostas e detecção de falhas de outros clientes. Nosso sistema, Zookeeper, portanto, implementa uma API que manipula objetos de dados simples e sem espera organizados hierarquicamente como em sistemas de arquivos. Na verdade, a API do ZooKeeper se assemelha a qualquer outro sistema de arquivos e, olhando apenas para as assinaturas da API, o ZooKeeper parece ser gordinho sem os métodos de bloqueio, abrir e fechar. A implementação de objetos de dados sem espera, no entanto, diferencia o ZooKeeper significativamente dos sistemas baseados em primitivos de bloqueio, como bloqueios.

Embora a propriedade sem espera seja importante para desempenho e tolerância a falhas, ela não é suficiente para coordenação. Também temos que fornecer garantias de pedidos para operações. Em particular, descobrimos que garantir tanto a ordem do cliente FIFO de todas as operações quanto a escrita linearizável permite uma implementação eficiente do serviço e é suficiente para implementar as primitivas de coordenação de interesse para nossas aplicações. De fato, podemos implementar o consenso para qualquer número de processos com nossa API e, de acordo com a hierarquia de Herlihy, o Zoo-Keeper implementa um objeto universal [14].

O serviço ZooKeeper compreende um conjunto de servidores que usam replicação para obter alta disponibilidade e desempenho. Seu alto desempenho permite que aplicativos que compreendem um grande número de processos usem tal núcleo de coordenação para gerenciar todos os aspectos da coordenação. Conseguimos implementar o ZooKeeper usando uma arquitetura de pipeline simples que nos permite ter centenas ou milhares de solicitações pendentes enquanto ainda atingimos baixa latência. Tal pipeline naturalmente permite a execução de operações de um único cliente na ordem FIFO. Garantir a ordem do cliente FIFO permite que os clientes enviem operações de forma assíncrona. Com operações assíncronas, um cliente pode ter várias operações pendentes por vez. Esse recurso é desejável, por exemplo, quando um novo cliente se torna líder e precisa manipular metadados e atualizá-los de acordo. Sem a possibilidade de múltiplas operações pendentes, o tempo de inicialização pode ser da ordem de segundos em vez de subsegundos.

Para garantir que as operações de atualização satisfaçam a capacidade de linearização, implementamos um protocolo de transmissão atômica baseado em líder [23], chamado Zab [24]. No ZooKeeper, os servidores processam as operações de leitura localmente e não usamos o Zab para ordená-las totalmente.

O cache de dados no lado do cliente é uma técnica importante para aumentar o desempenho das leituras. Por exemplo, é útil para um processo armazenar em cache o identificador do líder atual em vez de sondar o ZooKeeper toda vez que ele precisa conhecer o líder. O ZooKeeper usa um mecanismo de observação para permitir que os clientes armazenem dados em cache sem gerenciar o cache do cliente diretamente. Com esse mecanismo, um cliente pode observar uma atualização de um determinado objeto de dados e receber uma notificação sobre uma atualização. Chubby gerencia o cache do cliente diretamente. Ele bloqueia as atualizações para invalidar os caches de todos os clientes que armazenam em cache os dados que estão sendo alterados. Sob esse design, se algum desses clientes estiver lento ou com defeito, a atualização será atrasada. Chubby usa concessões para evitar que um cliente defeituoso bloqueie o sistema indefinidamente. Os aluguéis, no entanto, limitam apenas o impacto de clientes lentos ou defeituosos, enquanto os relógios ZooKeeper evitam o problema completamente.

Neste artigo, discutimos nosso projeto e implementação do ZooKeeper. Com o ZooKeeper, somos capazes de implementar todas as primitivas de coordenação que nossos aplicativos exigem, mesmo que apenas as gravações sejam linearizáveis. Para validar nossa abordagem, mostramos como implementamos algumas primitivas de coordenação com o ZooKeeper.

Em resumo, neste artigo, nossas principais contribuições são:

Núcleo de coordenação: Propomos um serviço de coordenação livre de espera com garantias de consistência relaxada para uso em sistemas distribuídos. Em particular, descrevemos nosso projeto e implementação de um kernel de coordenação, que usamos em muitos aplicativos críticos para implementar várias técnicas de coordenação.

Receitas de coordenação: Mostramos como o ZooKeeper pode ser usado para construir primitivas de coordenação de alto nível, mesmo bloqueantes e primitivas fortemente consistentes, que são freqüentemente usadas em aplicações distribuídas.

Experiência com coordenação: Compartilhamos algumas das maneiras como usamos o ZooKeeper e avaliamos seu desempenho.


2. O serviço ZooKeeper
Os clientes enviam solicitações ao ZooKeeper por meio de uma clientAPI usando uma biblioteca de cliente do ZooKeeper. Além de expor a interface do serviço ZooKeeper por meio do clientAPI, a biblioteca do cliente também gerencia as conexões de rede entre o cliente e os servidores ZooKeeper.

Nesta seção, primeiro fornecemos uma visão de alto nível do serviço ZooKeeper. Em seguida, discutimos a API que os clientes usam para interagir com o ZooKeeper.

Terminologia. Neste artigo, usamos client para denotar um usuário do serviço ZooKeeper, server para denotar um processo que fornece o serviço ZooKeeper e znode para denotar um nó de dados na memória nos dados do ZooKeeper, que é organizado em um namespace hierárquico conhecido como a árvore de dados. Também usamos os termos atualizar e escrever para nos referirmos a qualquer operação que modifique o estado da árvore de dados. Os clientes estabelecem uma sessão quando se conectam ao ZooKeeper e obtêm um identificador de sessão por meio do qual emitem solicitações.

2.1. Visão geral do serviço
O ZooKeeper fornece aos seus clientes a abstração de um conjunto de nós de dados (znodes), organizados de acordo com um namespace hierárquico. Os znodes nessa hierarquia são objetos de dados que os clientes manipulam por meio do ZooKeeperAPI. Espaços de nomes hierárquicos são comumente usados em sistemas de arquivos. É uma forma desejável de organizar os objetos de dados, pois os usuários estão acostumados com essa abstração e permite uma melhor organização dos metadados da aplicação. Para se referir a um determinado znode, usamos a notação padrão do UNIX para caminhos do sistema de arquivos. Por exemplo, usamos /A/B/C para denotar o caminho para znodeC, onde C tem B como pai e B tem A como pai. Todos os znodes armazenam dados e todos os znodes, exceto os znodes efêmeros, podem ter filhos.

Figura 1: Ilustração do namespace hierárquico do ZooKeeper.

Existem dois tipos de znodes que um cliente pode criar:

Regular: Os clientes manipulam znodes regulares criando e excluindo-os explicitamente;
Efêmero: os clientes criam esses znodes e os excluem explicitamente ou permitem que o sistema os remova automaticamente quando a sessão que os cria termina (deliberadamente ou devido a uma falha).

Além disso, ao criar um novo znode, um cliente pode definir um sinalizador sequencial. Os nós criados com o sinalizador seqüencial definido têm o valor de um contador de crescimento monotônico anexado ao seu nome. Se n for o novo znode e p for o znode pai, então o valor de sequência de n nunca será menor que o valor no nome de qualquer outro znode sequencial já criado sob p.

O ZooKeeper implementa inspeções para permitir que os clientes recebam notificações oportunas de alterações sem a necessidade de votação. Monitores são acionadores únicos associados a uma sessão; eles são cancelados uma vez acionados ou a sessão é encerrada. Os relógios indicam que uma alteração ocorreu, mas não fornecem a alteração. Por exemplo, se um cliente processa um getData(''/foo'', true) antes de "/foo" ser alterado duas vezes, o cliente receberá um evento de observação informando ao cliente que os dados de "/foo" foram alterados. Eventos de sessão, como eventos de perda de conexão, também são enviados para assistir retornos de chamada para que os clientes saibam que os eventos de observação podem ser atrasados.

Modelo de dados. O modelo de dados do ZooKeeper é essencialmente um sistema de arquivos com uma API simplificada e apenas leituras e gravações completas de dados ou uma tabela de chave/valor com chaves hierárquicas. O namespace hierárquico é útil para alocar subárvores para o namespace de diferentes aplicativos e para definir direitos de acesso a essas subárvores. Também exploramos o conceito de diretórios no lado do cliente para construir primitivas de nível superior, como veremos na seção 2.4.

Ao contrário dos arquivos em sistemas de arquivos, os znodes não são projetados para armazenamento de dados gerais. Em vez disso, znodes são mapeados para abstrações do aplicativo cliente, geralmente correspondendo a metadados usados para fins de coordenação. Para ilustrar, na Figura 1 temos duas subárvores, uma para o Aplicativo 1 (/app1) e outra para o Aplicativo 2 (/app2). , que persiste enquanto o processo estiver em execução.

Embora os znodes não tenham sido projetados para armazenamento de dados gerais, o ZooKeeper permite que os clientes armazenem algumas informações que podem ser usadas para metadados ou configuração em uma computação distribuída. Por exemplo, em um aplicativo baseado em líder, é útil para um servidor de aplicativos que está apenas começando a aprender qual outro servidor é atualmente o líder. Para atingir esse objetivo, podemos fazer com que o líder atual escreva essas informações em um local conhecido no espaço znode. Os Znodes também têm metadados associados com carimbos de data/hora e contadores de versão, que permitem aos clientes rastrear alterações nos znodes e executar atualizações condicionais com base na versão do znode.

Sessões. Um cliente se conecta ao ZooKeeper e inicia uma sessão. As sessões têm um tempo limite associado. O Zoo-Keeper considera um cliente com defeito se ele não receber nada de sua sessão por mais do que esse tempo limite. Uma sessão termina quando os clientes fecham explicitamente um manipulador de sessão ou o ZooKeeper detecta que um cliente está com defeito. Dentro de uma sessão, um cliente observa uma sucessão de mudanças de estado que refletem a execução de suas operações. As sessões permitem que um cliente se mova de forma transparente de um servidor para outro dentro de um conjunto ZooKeeper e, portanto, persista nos servidores ZooKeeper.

2.2 API do cliente
Apresentamos abaixo um subconjunto relevante do ZooKeeperAPI e discutimos a semântica de cada solicitação.

create(path, data, flags): Cria um znode com o nome do caminhopath, armazena data[] nele e retorna o nome do novo znode.flags permite que um cliente selecione o tipo de znode: regular, efêmero e defina o sequencial bandeira;

delete(path, version): Exclui o znodepath se esse znode estiver na versão esperada;

exists(path, watch):Retorna verdadeiro se o znode com o nome do caminhopath existir e retorna falso caso contrário. O sinalizador watch permite que um cliente defina um watch no znode;

getData(path, watch): Retorna os dados e metadados, como informações de versão, associados ao znode. O watchflag funciona da mesma forma que para existe(), exceto que o Zoo-Keeper não define o relógio se o znode não existir;

setData(path, data, version): Grava data[]para znodepath se o número da versão for a versão atual do znode;

getChildren(path, watch):Retorna o conjunto de nomes dos filhos de um znode;

sync(path): Aguarda que todas as atualizações pendentes no início da operação sejam propagadas para o servidor ao qual o cliente está conectado. O caminho é atualmente ignorado.

Todos os métodos têm versões síncronas e assíncronas disponíveis por meio da API. Um aplicativo usa a API síncrona quando precisa executar uma única operação do ZooKeeper e não tem tarefas simultâneas para executar, portanto, faz as chamadas e os blocos necessários do ZooKeeper. A API assíncrona, no entanto, permite que um aplicativo tenha várias operações pendentes do ZooKeeper e outras tarefas executadas em paralelo. O cliente ZooKeeper garante que os retornos de chamada correspondentes para cada operação sejam invocados em ordem.

Observe que o ZooKeeper não usa identificadores para acessar znodes. Em vez disso, cada solicitação inclui o caminho completo do znode que está sendo operado. Essa escolha não apenas simplifica a API (métodos noopen() ou close()), mas também elimina o estado extra que o servidor precisaria manter. atualizações adicionais. Se o número da versão real do znode não corresponder ao número da versão esperada, a atualização falhará com um erro de versão inesperado. Se o número da versão for -1, ele não executa a verificação de versão.

2.3 Garantias do ZooKeeper
O ZooKeeper tem duas garantias básicas de pedidos:

Gravações linearizáveis: todas as solicitações que atualizam o estado do ZooKeeper são serializáveis e respeitam a precedência;

Ordem do cliente FIFO: todas as solicitações de um determinado cliente são executadas na ordem em que foram enviadas pelo cliente.

Note que nossa definição de linearizabilidade é diferente da originalmente proposta por Herlihy [15], e a chamamos de linearizabilidade A (linearizabilidade assíncrona). Na definição original de linearizabilidade de Her-lihy, um cliente só pode ter uma operação pendente por vez (um cliente é uma thread). No nosso, permitimos que um cliente tenha múltiplas operações pendentes e, consequentemente, podemos optar por não garantir nenhuma ordem específica para operações pendentes do mesmo cliente ou garantir a ordem FIFO. Escolhemos o último para nossa propriedade. É importante observar que todos os resultados válidos para objetos linearizáveis também são válidos para objetos A-linearizáveis porque um sistema que satisfaz a linearizabilidade A também satisfaz a linearizabilidade. Como apenas as solicitações de atualização são linearizáveis em A, o ZooKeeper processa as solicitações de leitura localmente em cada réplica. Isso permite que o serviço seja dimensionado linearmente à medida que os servidores são adicionados ao sistema.

Para ver como essas duas garantias interagem, considere o seguinte cenário. Um sistema composto por vários processos elege um líder para comandar os processos trabalhadores. Quando um novo líder assume o comando do sistema, ele deve alterar um grande número de parâmetros de configuração e notificar os outros processos quando terminar. Temos então dois requisitos importantes:

- À medida que o novo líder começa a fazer alterações, não queremos que outros processos passem a usar a configuração que está sendo alterada;
- Se o novo líder morrer antes que a configuração tenha sido totalmente atualizada, não queremos que os processos usem essa configuração parcial.

Observe que os bloqueios distribuídos, como os bloqueios fornecidos pelo Chubby, ajudariam no primeiro requisito, mas são insuficientes para o segundo. Com o ZooKeeper, o novo líder pode designar um caminho como o znode pronto; outros processos só usarão a configuração quando esse znode existir. O novo líder faz a alteração de configuração excluindo ready, atualizando os vários znodes de configuração e criando ready. Todas essas alterações podem ser canalizadas e emitidas de forma assíncrona para atualizar rapidamente o estado de configuração. Embora a latência de uma operação de alteração seja da ordem de 2 milissegundos, um novo líder que deve atualizar 5.000 znodes diferentes levará 10 segundos se as solicitações forem emitidas uma após a outra; ao emitir as solicitações de forma assíncrona, as solicitações levarão menos de um segundo. Por causa das garantias de ordenação, se um processo vê o znode pronto, ele também deve ver todas as alterações de configuração feitas pelo novo líder. Se o novo líder morrer antes que o znode pronto seja criado, os outros processos saberão que a configuração não foi finalizada e não a usarão.

O esquema acima ainda tem um problema: o que acontece se um processo vê que já existe antes que o novo líder comece a fazer uma mudança e então comece a ler a configuração enquanto a mudança está em andamento. Esse problema é resolvido pela garantia de ordenação das notificações: se um cliente estiver observando uma alteração, o cliente verá o evento de notificação antes de ver o novo estado do sistema após a alteração. Conseqüentemente, se o processo que lê o znode pronto solicita ser notificado sobre alterações nesse znode, ele verá uma notificação informando o cliente sobre a alteração antes que ele possa ler qualquer uma das novas configurações.

Outro problema pode surgir quando os clientes têm seus próprios canais de comunicação além do ZooKeeper. Por exemplo, considere dois clientes A e B que têm uma configuração compartilhada no ZooKeeper e se comunicam por meio de um canal de comunicação compartilhado. Se A alterar a configuração compartilhada no ZooKeeper e informar a B sobre a alteração por meio do canal de comunicação compartilhado, B esperaria ver a alteração quando reler a configuração. Usando as garantias acima, B pode certificar-se de que vê as informações mais atualizadas emitindo uma gravação antes de reler a configuração. Para lidar com esse cenário com mais eficiência, o Zoo-Keeper fornece a solicitação de sincronização: quando seguida por uma leitura, constitui uma leitura lenta. A sincronização faz com que um servidor aplique todas as solicitações de gravação pendentes antes de processar a leitura sem a sobrecarga de uma gravação completa. Essa primitiva é semelhante em ideia à primitiva de descarga do ISIS [5].

O ZooKeeper também tem as duas garantias de vivacidade e durabilidade a seguir: se a maioria dos servidores ZooKeeper estiver ativa e comunicando, o serviço estará disponível; e se o serviço ZooKeeper responder com êxito a uma solicitação de alteração, essa alteração persistirá em qualquer número de falhas, desde que um quorum de servidores seja eventualmente capaz de se recuperar.

2.4 Exemplos de primitivas

Nesta seção, mostramos como usar a API do ZooKeeper para implementar primitivas mais poderosas. O serviço ZooKeeper não sabe nada sobre esses primitivos mais poderosos, pois eles são totalmente implementados no cliente usando a API do cliente ZooKeeper. Algumas primitivas comuns, como associação de grupo e gerenciamento de configuração, também são isentas de espera. Para outros, como rendezvous, os clientes precisam esperar por um evento. Embora o ZooKeeper seja livre de espera, podemos implementar primitivos de bloqueio eficientes com o ZooKeeper. As garantias de pedidos do ZooKeeper permitem um raciocínio eficiente sobre o estado do sistema, e os relógios permitem uma espera eficiente.

Gerenciamento de configuração: o ZooKeeper pode ser usado para implementar a configuração dinâmica em um aplicativo distribuído. Em sua forma mais simples, a configuração é armazenada em um znode,zc. Os processos iniciam com o nome de caminho completo de zc. Os processos iniciais obtêm sua configuração lendo zc com o sinalizador watch definido como verdadeiro. Se a configuração em zc for atualizada, os processos são notificados e leem a nova configuração, novamente definindo o watchflag como verdadeiro.
Observe que neste esquema, como na maioria dos outros que usam relógios, os relógios são usados para garantir que um processo tenha as informações mais recentes. Por exemplo, se um processo que monitora zc for notificado sobre uma alteração em zc e antes de emitir uma leitura para zc houver mais três alterações em zc, o processo não receberá mais três eventos de notificação. Isso não afeta o comportamento do processo, pois esses três eventos teriam simplesmente notificado o processo de algo que ele já sabe: a informação que ele tem para zc está obsoleta.

Rendezvous: Às vezes, em sistemas distribuídos, nem sempre é claro a priori como será a configuração final do sistema. Por exemplo, um cliente pode querer iniciar um processo mestre e vários processos de trabalho, mas o início dos processos é feito por um agendador, então o cliente não sabe com antecedência informações como endereços e portas que ele pode fornecer aos processos de trabalho para se conectar ao mestre . Lidamos com esse cenário com o Zoo-Keeper usando um rendezvous znode,zr, que é um nó criado pelo cliente. O cliente passa o caminho completo de zr como um parâmetro de inicialização dos processos master e worker. Quando o mestre inicia, ele preenche zr com informações sobre endereços e portas que está usando. Quando os trabalhadores iniciam, eles leem zr com watch definido como verdadeiro. Se zr ainda não tiver sido preenchido, o trabalhador espera ser notificado quando zr for atualizado. Se zr for um nó efêmero, os processos mestre e de trabalho podem observar a exclusão de zr e se limpar quando o cliente terminar.

Associação de grupo: aproveitamos os nós efêmeros para implementar a associação de grupo. Especificamente, usamos o fato de que nós efêmeros nos permitem ver o estado da sessão que criou o nó. Começamos designando um znode,zg para representar o grupo. Quando um membro do processo do grupo é iniciado, ele cria um znode filho efêmero em zg. Se cada processo tiver um nome ou identificador exclusivo, esse nome será usado como o nome do nó filho; caso contrário, o processo cria o znode com o sinalizador SEQUENTIAL para obter uma atribuição de nome exclusiva. Os processos podem colocar informações do processo nos dados do znode filho, endereços e portas usadas pelo processo, por exemplo.
Depois que o znode filho é criado em zg, o processo começa normalmente. Ele não precisa fazer mais nada. Se o processo falhar ou terminar, o znode que o representa sob zg é automaticamente removido.
Os processos podem obter informações de grupo simplesmente listando os filhos de zg. Se um processo deseja monitorar as alterações na associação do grupo, o processo pode definir o sinalizador de observação como verdadeiro e atualizar as informações do grupo (sempre definindo o sinalizador de observação como verdadeiro) quando as notificações de alteração são recebidas.

Bloqueios Simples: Embora o ZooKeeper não seja um serviço de bloqueio, ele pode ser usado para implementar bloqueios. Os aplicativos que usam o ZooKeeper geralmente usam primitivas de sincronização adaptadas às suas necessidades, como as mostradas acima. Aqui, mostramos como implementar bloqueios com o ZooKeeper para mostrar que ele pode implementar uma ampla variedade de primitivas de sincronização geral.
A implementação de bloqueio mais simples usa “arquivos de bloqueio”. O bloqueio é representado por um znode. Para adquirir um bloqueio, um cliente tenta criar o znode designado com o sinalizador EFÊMERO. Se a criação for bem-sucedida, o cliente mantém o bloqueio. Caso contrário, o cliente pode ler o zn-ode com o sinalizador de observação definido para ser notificado se o líder atual morrer. Um cliente libera o bloqueio quando ele morre ou exclui explicitamente o znode. Outros clientes que estão esperando por um bloqueio tentam novamente adquirir um bloqueio assim que observarem que o znode está sendo excluído.
Embora esse protocolo de bloqueio simples funcione, ele apresenta alguns problemas. Primeiro, sofre com o efeito manada. Se houver muitos clientes esperando para adquirir um bloqueio, todos eles disputarão o bloqueio quando ele for liberado, embora apenas um cliente possa adquirir o bloqueio. Em segundo lugar, ele apenas implementa bloqueio exclusivo. As duas primitivas a seguir mostram como esses dois problemas podem ser superados.

Bloqueios Simples sem Efeito de Manada: Definimos um lockznodel para implementar tais bloqueios. Intuitivamente alinhamos todos os clientes solicitando o bloqueio e cada cliente obtém o bloqueio por ordem de chegada do pedido. Assim, os clientes que desejam obter o bloqueio devem fazer o seguinte:

Lock
1 n = create(l +“/lock-”, EPHEMERAL|SEQUENTIAL)
2 C = getChildren(l, false)
3 if n is lowest znode in C, exit
4 p = znode in C ordered just before n
5 ifexists(p, true) wait for watch event
6 goto 2

Unlock
1 delete(n)

O uso do sinalizador SEQUENTIAL na linha 1 de Lock ordena a tentativa do cliente de adquirir o bloqueio em relação a todas as outras tentativas. Se o znode do cliente tiver o menor número de sequência na linha 3, o cliente manterá o bloqueio. Caso contrário, o cliente aguarda a exclusão do zn-ode que possui o bloqueio ou receberá o bloqueio antes do znode desse cliente. Observando apenas o znode que precede o znode do cliente, evitamos o efeito rebanho, ativando apenas um processo quando um bloqueio é liberado ou uma solicitação de bloqueio é abandonada. Depois que o znode sendo observado pelo cliente desaparece, o cliente deve verificar se agora ele contém o bloqueio. (A solicitação de bloqueio anterior pode ter sido abandonada e há um znode com um número de sequência inferior ainda esperando ou retendo o bloqueio.)
Liberar um bloqueio é tão simples quanto excluir o zn-oden que representa a solicitação de bloqueio. Ao usar o sinalizador EPHEMERAL na criação, os processos que falham limpam automaticamente quaisquer solicitações de bloqueio ou liberam quaisquer bloqueios que possam ter.

Em resumo, este esquema de bloqueio tem as seguintes vantagens:

1. A remoção de um znode faz com que apenas um cliente acorde, já que cada znode é assistido por exatamente um outro cliente, então não temos o efeito manada;
2. Não há polling ou timeouts;
3. Devido à maneira como implementamos o bloqueio, podemos ver, navegando nos dados do ZooKeeper, a quantidade de contenção de bloqueio, quebra de bloqueio e problemas de depuração de bloqueio.

Bloqueios de leitura/gravação: Para implementar os bloqueios de leitura/gravação, alteramos ligeiramente o procedimento de bloqueio e separamos os procedimentos de bloqueio de leitura e bloqueio de gravação. O procedimento de desbloqueio é igual ao da fechadura global.

Write  Lock
1  n = create(l +“/write-”, EPHEMERAL|SEQUENTIAL)
2  C = getChildren(l, false)
3  ifn is lowest znode in C, exit
4  p = znode in C ordered just before n
5  ifexists(p, true) wait for event
6  goto 2

Read  Lock
1  n = create(l +“/read-”, EPHEMERAL|SEQUENTIAL)
2  C = getChildren(l, false)
3  if no write znodes lower than n in C, exit
4  p = write znode in C ordered just before n
5  ifexists(p, true) wait for event
6  goto 3

Este procedimento de bloqueio varia ligeiramente dos bloqueios anteriores. Os bloqueios de gravação diferem apenas na nomenclatura. Como os bloqueios de leitura podem ser compartilhados, as linhas 3 e 4 variam um pouco porque somente os znodes de bloqueio de gravação anteriores impedem que o cliente obtenha um bloqueio de leitura. Pode parecer que temos um “efeito herd” quando há vários clientes esperando por um readlock e somos notificados quando o nó z “write-” com o menor número de sequência é excluído; na verdade, este é um comportamento desejado, todos esses clientes lidos devem ser liberados, pois agora podem ter o bloqueio.

Barreira dupla As barreiras duplas permitem que os clientes sincronizem o início e o fim de uma computação. Quando processos suficientes, definidos pelo limiar da barreira, se juntam à barreira, os processos iniciam sua computação e deixam a barreira assim que terminam. Representamos uma barreira no ZooKeeper com um znode, referido como b. Todo processo p se registra com b – criando um znode como filho de b – na entrada e cancela o registro – remove o filho – quando está pronto para sair. Os processos podem entrar na barreira quando o número de znodes filhos de b exceder o limite da barreira. Os processos podem deixar a barreira quando todos os processos tiverem removido seus filhos. Usamos relógios para esperar com eficiência que as condições de entrada e saída sejam satisfeitas. Para entrar, os processos observam a existência de um filho pronto de b que será criado pelo processo que faz com que o número de filhos exceda o limite da barreira. Para sair, os processos observam o desaparecimento de um determinado filho e só verificam a condição de saída quando esse znode for removido.



3 Aplicativos ZooKeeper
Agora descrevemos alguns aplicativos que usam o ZooKeeper e explicamos brevemente como eles o usam. Mostramos os primitivos de cada exemplo em negrito.

O serviço de busca: o rastreamento é uma parte importante de um mecanismo de pesquisa, e o Yahoo! rastreia bilhões de documentos da Web. O Fetching Service (FS) faz parte do Yahoo! crawler e está atualmente em produção. Essencialmente, ele possui processos mestres que comandam os processos de busca de páginas. O mestre fornece aos fetchers a configuração, e os fetchers escrevem de volta informando sobre seu status e saúde. As principais vantagens de usar o ZooKeeper para FS são a recuperação de falhas dos mestres, a garantia de disponibilidade apesar das falhas e o desacoplamento dos clientes dos servidores, permitindo que eles direcionem sua solicitação para servidores saudáveis apenas lendo seu status no ZooKeeper. Assim, FS usa ZooKeeper principalmente para gerenciar metadados de configuração de idade, embora também use Zoo-Keeper para eleger mestres (eleição de líder).

Figura 2: Carga de trabalho para um servidor ZK com FetchingService. Cada ponto representa uma amostra de um segundo.

A Figura 2 mostra o tráfego de leitura e gravação para um servidor Zoo-Keeper usado pelo FS durante um período de três dias. Para gerar esse gráfico, contamos o número de operações por segundo durante o período, e cada ponto corresponde ao número de operações naquele segundo. Observamos que o tráfego de leitura é muito maior comparado ao tráfego de gravação. Nos períodos em que a taxa é superior a 1.000 operações por segundo, a relação leitura:gravação varia entre 10:1 e 100:1. As operações de leitura nessa carga de trabalho são getData(), getChildren() eexists(), em ordem crescente de prevalência.

Katta: Katta [17] é um indexador distribuído que usa o Zoo-Keeper para coordenação e é um exemplo de um não-Yahoo! aplicativo. Katta divide o trabalho de indexação usando shards. Um servidor mestre atribui shards a escravos e rastreia o progresso. Os escravos podem falhar, então o mestre deve redistribuir a carga conforme os escravos vêm e vão. O mestre também pode falhar, então outros servidores devem estar prontos para assumir o controle em caso de falha. Katta usa o ZooKeeper para rastrear o status dos servidores escravos e do mestre (associação ao grupo) e para lidar com o failover do mestre (eleição do líder). Kattatambém usa o ZooKeeper para rastrear e propagar as atribuições de fragmentos para escravos (gerenciamento de configuração).

Yahoo! Corretor de mensagensYahoo! Message Broker(YMB) é um sistema distribuído de publicação-assinatura. O sistema gerencia milhares de tópicos nos quais os clientes podem publicar e receber mensagens. Os tópicos são distribuídos entre um conjunto de servidores para fornecer escalabilidade. Cada tópico é replicado usando um esquema de backup primário que garante que as mensagens sejam replicadas para duas máquinas para garantir a entrega confiável de mensagens. Os servidores que compõem o YMB usam uma arquitetura distribuída sem compartilhamento que torna a coordenação essencial para a operação correta. O YMB usa o ZooKeeper para gerenciar a distribuição de tópicos (metadados de configuração), lidar com falhas de máquinas no sistema (detecção de falhas e participação em grupos) e controlar a operação do sistema.

Figura 3: O layout do Yahoo! Estruturas do Message Broker (YMB) no ZooKeeper

A Figura 3 mostra parte do layout de dados do znode para YMB. Cada domínio do broker possui um znode chamado nodes, que possui um znode efêmero para cada um dos servidores ativos que compõem o serviço YMB. Cada servidor YMB cria um znode efêmero sob nós com informações de carga e status, fornecendo informações de status e membros do grupo por meio do ZooKeeper. Nós como desligamento e migração proibida são monitorados por todos os servidores que compõem o serviço e permitem o controle centralizado do YMB. O diretório de tópicos tem um znode filho para cada tópico gerenciado pelo YMB. Esses znodes de tópico têm znodes filhos que indicam o servidor primário e de backup para cada tópico junto com os assinantes desse tópico. Os znodes do servidor principal e de backup não apenas permitem que os servidores descubram os servidores encarregados de um tópico, mas também gerenciam a eleição do líder e as falhas do servidor.

Figura 4: Os componentes do serviço ZooKeeper.



4 Implementação do ZooKeeper
O ZooKeeper fornece alta disponibilidade replicando os dados do ZooKeeper em cada servidor que compõe o serviço. Assumimos que os servidores falham por travamento e esses servidores defeituosos podem se recuperar posteriormente. A Figura 4 mostra os componentes de alto nível do serviço ZooKeeper. Ao receber uma solicitação, um servidor a prepara para execução (processador de solicitação). Se tal solicitação exigir coordenação entre os servidores (solicitações de gravação), então eles usam um protocolo de acordo (uma implementação de transmissão atômica) e, finalmente, os servidores confirmam as alterações no banco de dados do Zoo-Keeper totalmente replicado em todos os servidores do conjunto. No caso de solicitações de leitura, um servidor simplesmente lê o estado do banco de dados local e gera uma resposta à solicitação.

O banco de dados replicado é um banco de dados na memória que contém toda a árvore de dados. Cada znode na árvore armazena no máximo 1MB de dados por padrão, mas esse valor máximo é um parâmetro de configuração que pode ser alterado em casos específicos. Para capacidade de recuperação, registramos com eficiência as atualizações no disco e forçamos as gravações na mídia do disco antes de serem aplicadas ao banco de dados na memória. De fato, como Chubby [8], mantemos um log de replay (um write-aheadlog, em nosso caso) das operações confirmadas e geramos instantâneos periódicos do banco de dados na memória.

Cada servidor ZooKeeper atende clientes. Os clientes se conectam a exatamente um servidor para enviar suas solicitações. Como observamos anteriormente, as solicitações de leitura são atendidas a partir da réplica local de cada banco de dados do servidor. Solicitações que alteram o estado do serviço, solicitações de gravação, são processadas por um protocolo de contrato.

Como parte do contrato, as solicitações de gravação do protocolo são encaminhadas para um único servidor, chamado de líder1. O resto dos servidores do ZooKeeper, chamados seguidores, recebem propostas de mensagens que consistem em mudanças de estado do líder e concordam com as mudanças de estado.

4.1 Processador de Pedidos
Como a camada de mensagens é atômica, garantimos que as réplicas locais nunca divergem, embora em algum momento alguns servidores possam ter aplicado mais transações do que outros. Ao contrário das requisições enviadas pelos clientes, as transações são idempotentes. Quando o líder recebe uma solicitação de gravação, ele calcula qual será o estado do sistema quando a gravação for aplicada e o transforma em uma transação que captura esse novo estado. O estado futuro deve ser calculado porque pode haver transações pendentes que ainda não foram aplicadas ao banco de dados. Por exemplo, se um cliente fizer um setData condicional e o número da versão na solicitação corresponder ao número da versão futura do znode que está sendo atualizado, o serviço gerará um setDataTXN que contém os novos dados, o novo número da versão e os registros de data e hora atualizados. Se ocorrer um erro, como números de versão incompatíveis ou se o znode a ser atualizado não existir, um erroTXN será gerado.

4.2 Transmissão Atômica
Todas as requisições que atualizam o estado do ZooKeeper são encaminhadas para o líder. O líder executa a requisição e transmite a mudança para o estado do ZooKeeper através do Zab [24], um protocolo de transmissão atômica. O servidor que recebe a solicitação do cliente responde ao cliente quando ele entrega a mudança de estado correspondente. O Zab usa, por padrão, quóruns de maioria simples para decidir sobre uma proposta, portanto, o Zab e, portanto, o ZooKeeper só podem funcionar se a maioria dos servidores estiver correta (ou seja, com 2f + 1 servidor, podemos tolerar falhas).

Para obter uma alta taxa de transferência, o ZooKeeper tenta manter o pipeline de processamento de solicitação cheio. Pode ter milhares de requisições em diferentes partes do pipeline de processamento. Como as mudanças de estado dependem da aplicação das mudanças de estado anteriores, o Zab fornece garantias de ordem mais fortes do que a transmissão atômica regular. Mais especificamente, o Zab garante que as alterações transmitidas por um líder sejam entregues na ordem em que foram enviadas e todas as alterações dos líderes anteriores sejam entregues a um líder estabelecido antes que ele transmita suas próprias alterações.

Existem alguns detalhes de implementação que simplificam nossa implementação e nos dão um excelente desempenho. Usamos TCP para nosso transporte, então a ordem das mensagens é mantida pela rede, o que nos permite simplificar nossa implementação. Utilizamos o líder escolhido por Zab como o líder ZooKeeper, para que o mesmo processo que cria as transações também as proponha. Usamos o log para acompanhar as propostas como o log write-ahead para o banco de dados na memória, para que não tenhamos que gravar mensagens duas vezes no disco.

Durante a operação normal, o Zab entrega todas as mensagens em ordem e exatamente uma vez, mas como o Zab não registra persistentemente o id de cada mensagem entregue, o Zab pode reenviar uma mensagem durante a recuperação. Como usamos transações idempotentes, a entrega múltipla é aceitável, desde que sejam entregues em ordem. Na verdade, o ZooKeeper exige que o Zab entregue novamente pelo menos todas as mensagens que foram entregues após o início do último instantâneo

4.3 Banco de Dados Replicado
Cada réplica tem uma cópia na memória do ZooKeeperstate. Quando um servidor ZooKeeper se recupera de uma falha, ele precisa recuperar esse estado interno. Reproduzir todas as mensagens entregues para recuperar o estado levaria um tempo proibitivo depois de executar o servidor por um tempo, então o ZooKeeper usa instantâneos periódicos e requer apenas a reentrega de mensagens desde o início do instantâneo. Chamamos os instantâneos do Zoo-Keeper de instantâneos difusos, pois não bloqueamos o estado do ZooKeeper para tirar o instantâneo; em vez disso, fazemos uma primeira varredura profunda da árvore lendo atomicamente os dados e metadados de cada zn-ode e gravando-os no disco. Como o instantâneo difuso resultante pode ter aplicado algum subconjunto das alterações de estado fornecidas durante a geração do instantâneo, o resultado pode não corresponder ao estado do ZooKeeper em nenhum momento. No entanto, como as mudanças de estado são idempotentes, podemos aplicá-las duas vezes, desde que apliquemos as mudanças de estado na ordem.

Por exemplo, suponha que em uma árvore de dados do ZooKeeper dois nós/fooe/goo tenham valores f1 e g1 respectivamente e ambos estejam na versão 1 quando o instantâneo difuso começa, e o seguinte fluxo de mudanças de estado chega com a forma〈transaçãoTipo, caminho, valor, novo -versão>

〈SetDataTXN, /foo, f2, 2〉
〈SetDataTXN, /goo, g2, 2〉
〈SetDataTXN, /foo, f3, 3〉

Depois de processar essas alterações de estado, /fooand/goohave valuesf3andg2with versões 3 e 2,respectivamente. No entanto, o instantâneo difuso pode ter registrado que /fooe/gootem os valores f3 eg1 com as versões 3 e 1, respectivamente, o que não era um estado válido da árvore de dados do ZooKeeper. Se o servidor travar e se recuperar com esse instantâneo e o Zab entregar novamente as alterações de estado, o estado resultante corresponderá ao estado do serviço antes da falha.

4.4 Interações Cliente-Servidor
Quando um servidor processa uma solicitação de gravação, ele também envia e limpa notificações relativas a qualquer relógio que corresponda a essa atualização. Os servidores processam gravações em ordem e não processam outras gravações ou leituras simultaneamente. Isso garante uma sucessão estrita de notificações. Observe que os servidores lidam com as notificações localmente. Somente o servidor ao qual um cliente está conectado rastreia e aciona notificações para esse cliente.

As solicitações de leitura são tratadas localmente em cada servidor. Cada solicitação de leitura é processada e marcada com um azxid que corresponde à última transação vista pelo servidor. Thiszxiddefine a ordem parcial das solicitações de leitura em relação às solicitações de gravação. Ao processar leituras localmente, obtemos excelente desempenho de leitura porque é apenas uma operação na memória no servidor local e não há atividade de disco ou protocolo de contrato a ser executado. Essa escolha de design é fundamental para alcançar nosso objetivo de excelente desempenho com cargas de trabalho com leitura dominante.

Uma desvantagem de usar leituras rápidas é não garantir ordem de precedência para operações de leitura. Ou seja, uma operação de leitura pode retornar um valor obsoleto, mesmo que uma atualização mais recente para o mesmo znode tenha sido confirmada. Nem todos os nossos aplicativos exigem ordem de precedência, mas para aplicativos que exigem isso, implementamos o sync. Essa primitiva executa de forma assíncrona e é ordenada pelo líder após todas as gravações pendentes em sua réplica local. Para garantir que uma determinada operação de leitura retorne o valor atualizado mais recente, um cliente chama o sync seguido pela operação de leitura. A garantia de ordem FIFO das operações do cliente, juntamente com a garantia global de sincronização, permite que o resultado da operação de leitura reflita quaisquer alterações ocorridas antes da emissão da sincronização. o fim da fila de requisições entre o líder e o servidor que executa a chamada para sincronizar. Para que isso funcione, o seguidor deve ter certeza de que o líder ainda é o líder. Se houver transações pendentes que confirmem, o servidor não suspeitará do líder. Se a fila pendente estiver vazia, o líder precisa emitir uma transação nula para confirmar e ordena a sincronização após essa transação. Isso tem a boa propriedade de que, quando o líder está sob carga, nenhum tráfego de transmissão extra é gerado. Em nossa implementação, os tempos limite são definidos de forma que os líderes percebam que não são líderes antes que os seguidores os abandonem, portanto, não emitimos a transação nula.

Os servidores ZooKeeper processam solicitações de clientes na ordem FIFO. As respostas incluem o zxid ao qual a resposta é relativa. Mesmo mensagens de pulsação durante intervalos sem atividade incluem o último zxid visto pelo servidor ao qual o cliente está conectado. Se o cliente se conectar a um novo servidor, esse novo servidor garantirá que sua visualização dos dados do Zoo-Keeper seja pelo menos tão recente quanto a visualização do cliente, verificando o lastzxido do cliente em relação ao seu lastzxid. Se o cliente tiver uma visualização mais recente que o servidor, o servidor não restabelece a sessão com o cliente até que o servidor tenha alcançado. O cliente tem a garantia de encontrar outro servidor que tenha uma visão recente do sistema, pois o cliente vê apenas as alterações que foram replicadas para a maioria dos servidores do ZooKeeper. Esse comportamento é importante para garantir a durabilidade.

Para detectar falhas na sessão do cliente, o ZooKeeper usa limites de tempo. O líder determina que houve uma falha se nenhum outro servidor receber nada de uma sessão do cliente dentro do tempo limite da sessão. Se o cliente enviar solicitações com frequência suficiente, não há necessidade de enviar nenhuma outra mensagem. Caso contrário, o cliente enviará mensagens de pulsação durante os períodos de baixa atividade. Se o cliente não puder se comunicar com um servidor para enviar uma solicitação ou pulsação, ele se conectará a um servidor ZooKeeper diferente para restabelecer sua sessão. Para evitar que a sessão atinja o tempo limite, a biblioteca do cliente ZooKeeper envia uma pulsação após a sessão ficar ociosa por 3ms e mudar para um novo servidor se não tiver ouvido de um servidor por 2s/3ms, onde é o tempo limite da sessão em milissegundos.



5 Avaliação
Realizamos toda a nossa avaliação em um cluster de 50 servidores. Cada servidor possui um processador Xeon dual-core de 2,1 GHz, 4 GB de RAM, gigabit ethernet e dois discos rígidos SATA. Dividimos a discussão a seguir em duas partes: throughput e latência das requisições.

5.1 Rendimento
Para avaliar nosso sistema, comparamos a taxa de transferência quando o sistema está saturado e as mudanças na taxa de transferência para várias falhas injetadas. Variamos a quantidade de servidores que compõem o serviço ZooKeeper, mas mantivemos sempre a mesma quantidade de clientes. Para simular um grande número de clientes, utilizamos 35 máquinas para simular 250 clientes simultâneos.

Temos uma implementação Java do ZooKeeperserver e clientes Java e C2. Para esses experimentos, usamos o servidor Java configurado para fazer logon em um disco dedicado e tirar instantâneos em outro. Nosso cliente de referência usa a API de cliente Java assíncrona e cada cliente tem pelo menos 100 solicitações pendentes. Cada solicitação consiste em uma leitura ou gravação de 1K de dados. Não mostramos benchmarks para outras operações, pois o desempenho de todas as operações que modificam o estado é aproximadamente o mesmo, e o desempenho das operações de modificação sem estado, excluindo a sincronização, é aproximadamente o mesmo. (O desempenho de sincronização se aproxima do de uma gravação leve, já que a solicitação deve ir para o líder, mas não é transmitida.) Os clientes enviam contagens do número de operações concluídas a cada 300 ms e fazemos amostragens a cada 6 segundos. Para evitar estouros de memória, os servidores limitam o número de solicitações simultâneas no sistema. O ZooKeeper usa limitação de solicitação para evitar que os servidores sejam sobrecarregados. Para esses experimentos, configuramos os servidores ZooKeeper para ter um máximo de 2.000 solicitações totais em processo.

Figura 5: O desempenho da taxa de transferência de um sistema saturado conforme a proporção de leituras para gravações varia

Tabela 1: O desempenho de throughput dos extremos de um sistema saturado.

Na Figura 5, mostramos a taxa de transferência à medida que variamos a proporção de solicitações de leitura para gravação, e cada curva corresponde a um número diferente de servidores que fornecem o serviço ZooKeeper. A Tabela 1 mostra os números nos extremos das cargas lidas. A taxa de transferência de leitura é maior que a taxa de gravação porque as leituras não usam transmissão atômica. O gráfico também mostra que o número de servidores também tem um impacto negativo no desempenho do protocolo de transmissão. A partir desses gráficos, observamos que o número de servidores no sistema não afeta apenas o número de falhas que o serviço pode suportar, mas também a carga de trabalho que o serviço pode suportar. Observe que a curva de três servidores cruza as demais em torno de 60%. Esta situação não é exclusiva da configuração de três servidores, e ocorre para todas as configurações devido ao paralelismo que as leituras locais permitem. No entanto, não é observável para outras configurações na figura, porque limitamos a taxa de transferência máxima do eixo y para facilitar a leitura.

Há dois motivos para as solicitações de gravação demorarem mais do que as solicitações de leitura. Primeiro, as solicitações de gravação devem passar pela transmissão atômica, o que requer algum processamento extra e adiciona latência às solicitações. A outra razão para o processamento mais longo de solicitações de gravação é que os servidores devem garantir que as transações sejam registradas no armazenamento não volátil antes de enviar as confirmações de volta ao líder. Em princípio, esse requisito é excessivo, mas para nossos sistemas de produção, trocamos desempenho por confiabilidade, pois o ZooKeeper constitui a verdade básica do aplicativo. Usamos mais servidores para tolerar mais falhas. Aumentamos a taxa de gravação particionando os dados do ZooKeeper em vários conjuntos ZooKeeper. Essa troca de desempenho entre replicação e particionamento foi observada anteriormente por Gray et al.[12].

Figura 6: Taxa de transferência de um sistema saturado, variando a proporção de leituras para gravações quando todos os clientes se conectam ao líder.

O ZooKeeper é capaz de alcançar uma taxa de transferência tão alta distribuindo a carga entre os servidores que compõem o serviço. Podemos distribuir a carga por causa de nossas garantias de consistência relaxada. Em vez disso, clientes gordinhos direcionam todos os pedidos ao líder. A Figura 6 mostra o que acontece se não aproveitarmos esse relaxamento e forçarmos os clientes a se conectarem apenas ao líder. Como esperado, a taxa de transferência é muito menor para cargas de trabalho dominantes de leitura, mas mesmo para cargas de trabalho dominantes de gravação, a taxa de transferência é menor. A carga extra de CPU e rede causada pelos clientes de atendimento afeta a capacidade do líder de coordenar a transmissão das propostas, o que, por sua vez, afeta adversamente o desempenho geral da gravação.

O protocolo de transmissão atômica faz a maior parte do trabalho do sistema e, portanto, limita o desempenho do Zoo-Keeper mais do que qualquer outro componente. A Figura 7 mostra a taxa de transferência do componente de transmissão atômica. Para comparar seu desempenho, simulamos clientes gerando as transações diretamente no líder, para que não haja conexões de clientes ou solicitações e respostas de clientes. Na taxa de transferência máxima, o componente de transmissão atômica torna-se vinculado à CPU. Em teoria, o desempenho da Figura 7 corresponderia ao desempenho do ZooKeeper com 100% de gravações. No entanto, a comunicação do cliente ZooKeeper, as verificações de ACL e a solicitação para conversões de transação requerem CPU. A contenção da CPU reduz a taxa de transferência do ZooKeeper para substancialmente menos do que o componente de transmissão atômica isoladamente. Como o Zoo-Keeper é um componente crítico de produção, até agora nosso foco de desenvolvimento para o ZooKeeper tem sido correção e robustez. Existem muitas oportunidades para melhorar significativamente o desempenho, eliminando coisas como cópias extras, várias serializações do mesmo objeto, estruturas de dados internas mais eficientes, etc.

Figura 7: Taxa de transferência média do componente de transmissão atômica isoladamente. As barras de erro indicam os valores mínimo e máximo.

Figura 8: Taxa de transferência após falhas.

Para mostrar o comportamento do sistema ao longo do tempo conforme as falhas são injetadas, executamos um serviço ZooKeeper composto por 5 máquinas. Executamos o mesmo benchmark de saturação de antes, mas desta vez mantivemos a porcentagem de gravação em 30% constante, que é uma proporção conservadora de nossas cargas de trabalho esperadas. Periodicamente nós matamos alguns dos processos do servidor. A Figura 8 mostra o throughput do sistema conforme ele muda com o tempo. Os eventos marcados na figura são os seguintes:

1. Falha e recuperação de um seguidor;
2. Falha e recuperação de um seguidor diferente;
3. Falha do líder;
4. Falha de dois seguidores (a, b) nas duas primeiras marcas, e recuperação na terceira marca (c);
5. Falha do líder.
6. Recuperação do líder.

Existem algumas observações importantes deste gráfico. Primeiro, se os seguidores falharem e se recuperarem rapidamente, o ZooKeeper será capaz de manter um alto rendimento apesar da falha. A falha de um único seguidor não impede que os servidores formem um quorum e apenas reduz a taxa de transferência aproximadamente pela parcela de solicitações de leitura que o servidor estava processando antes de falhar. Em segundo lugar, nosso algoritmo de eleição de líder é capaz de se recuperar rápido o suficiente para impedir que a taxa de transferência caia substancialmente. Em nossas observações, o ZooKeeper leva menos de 200 ms para eleger um novo líder. Assim, embora os servidores parem de atender requisições por uma fração de segundo, não observamos um throughput de zero devido ao nosso período de amostragem, que é da ordem de segundos. Em terceiro lugar, mesmo que os seguidores demorem mais para se recuperar, o ZooKeeper pode aumentar a taxa de transferência novamente quando eles começam a processar as solicitações. Uma razão pela qual não recuperamos o nível de taxa de transferência total após os eventos 1, 2 e 4 é que os clientes só trocam de seguidores quando sua conexão com o seguidor é interrompida. Assim, após o evento 4, os clientes não se redistribuem até que o líder falhe nos eventos 3 e 5. Na prática, esses desequilíbrios se resolvem com o tempo, à medida que os clientes vão e vêm.

5.2 Latency of requests
To  assess  the  latency  of  requests,  we  created  a  bench-mark modeled after the Chubby benchmark [6]. We cre-ate  a  worker  process  that  simply  sends  a  create,  waitsfor it to finish, sends an asynchronous delete of the newnode, and then starts the next create. We vary the numberof workers accordingly, and for each run, we have eachworker create 50,000 nodes. We calculate the throughputby dividing the number of create requests completed bythe total time it took for all the workers to complete.

Table 2: Create requests processed per second.

Table 2 show the results of our benchmark.  The cre-ate  requests  include  1K  of  data,  rather  than  5  bytes  inthe Chubby benchmark, to better coincide with our ex-pected use. Even with these larger requests, the through-put of ZooKeeper is more than 3 times higher than thepublished throughput of Chubby.  The throughput of thesingle ZooKeeper worker benchmark indicates that theaverage  request  latency  is1.2ms  for  three  servers  and1.4ms for 9 servers.

Table 3:  Barrier experiment with time in seconds.  Eachpoint is the average of the time for each client to finishover five runs.

5.3 Performance of barriers
In this experiment, we execute a number of barriers se-quentially to assess the performance of primitives imple-mented with ZooKeeper. For a given number of barriersb, each client first enters allbbarriers, and then it leavesallbbarriers in succession. As we use the double-barrieralgorithm of Section 2.4, a client first waits for all otherclients to execute theenter()procedure before mov-ing to next call (similarly forleave())

We report the results of our experiments in Table 3.In  this  experiment,  we  have50,100,  and200clientsentering  a  numberbof  barriers  in  succession,b∈{200,400,800,1600}. Although an application can havethousands  of  ZooKeeper  clients,  quite  often  a  muchsmaller  subset  participates  in  each  coordination  oper-ation  as  clients  are  often  grouped  according  to  thespecifics of the application.

Two interesting observations from this experiment arethat the time to process all barriers increase roughly lin-early with the number of barriers, showing that concur-rent access to the same part of the data tree did not pro-duce  any  unexpected  delay,  and  that  latency  increasesproportionally to the number of clients.  This is a con-sequence  of  not  saturating  the  ZooKeeper  service.   Infact,  we  observe  that  even  with  clients  proceeding  inlock-step, the throughput of barrier operations (enter andleave) is between 1,950 and 3,100 operations per secondin all cases.  In ZooKeeper operations, this correspondsto throughput values between 10,700 and 17,000 opera-tions per second.  As in our implementation we have aratio of reads to writes of 4:1 (80% of read operations),the throughput our benchmark code uses is much lowercompared to the raw throughput ZooKeeper can achieve(over 40,000 according to Figure 5). This is due to clientswaiting on other clients.



6 Related work
ZooKeeper has the goal of providing a service that mit-igates  the  problem  of  coordinating  processes  in  dis-tributed applications. To achieve this goal, its design usesideas from previous coordination services, fault tolerantsystems, distributed algorithms, and file systems.

We are not the first to propose a system for the coor-dination of distributed applications. Some early systemspropose a distributed lock service for transactional ap-plications  [13],  and  for  sharing  information  in  clustersof computers [19].   More recently,  Chubby proposes asystem to manage advisory locks for distributed appli-cations [6].  Chubby shares several of the goals of Zoo-Keeper. It also has a file-system-like interface, and it usesan agreement protocol to guarantee the consistency of thereplicas.  However, ZooKeeper is not a lock service.  Itcan be used by clients to implement locks, but there areno lock operations in its API. Unlike Chubby, ZooKeeperallows clients to connect to any ZooKeeper server,  notjust  the  leader.   ZooKeeper  clients  can  use  their  localreplicas to serve data and manage watches since its con-sistency model is much more relaxed than Chubby. Thisenables ZooKeeper to provide higher performance thanChubby,  allowing applications to make more extensiveuse of ZooKeeper.

There  have  been  fault-tolerant  systems  proposed  inthe literature with the goal of mitigating the problem ofbuilding fault-tolerant distributed applications. One earlysystem is ISIS [5].  The ISIS system transforms abstracttype specifications into fault-tolerant distributed objects,thus  making  fault-tolerance  mechanisms  transparent  tousers.   Horus [30] and Ensemble [31] are systems thatevolved  from  ISIS.  ZooKeeper  embraces  the  notion  ofvirtual synchrony of ISIS. Finally, Totem guarantees totalorder of message delivery in an architecture that exploitshardware broadcasts of local area networks [22].  Zoo-Keeper works with a wide variety of network topologieswhich motivated us to rely on TCP connections betweenserver processes and not assume any special topology orhardware features. We also do not expose any of the en-semble communication used internally in ZooKeeper.

One  important  technique  for  building  fault-tolerantservices is state-machine replication [26], and Paxos [20]is  an  algorithm  that  enables  efficient  implementationsof replicated state-machines for asynchronous systems.We use an algorithm that shares some of the character-istics  of  Paxos,  but  that  combines  transaction  loggingneeded for consensus with write-ahead logging neededfor data tree recovery to enable an efficient implementa-tion. There have been proposals of protocols for practicalimplementations  of  Byzantine-tolerant  replicated  state-machines [7, 10, 18, 1, 28]. ZooKeeper does not assumethat servers can be Byzantine, but we do employ mech-anisms  such  as  checksums  and  sanity  checks  to  catchnon-malicious  Byzantine  faults.    Clementet al.dis-cuss  an  approach  to  make  ZooKeeper  fully  Byzantinefault-tolerant without modifying the current server codebase [9]. To date, we have not observed faults in produc-tion that would have been prevented using a fully Byzan-tine fault-tolerant protocol. [29].

Boxwood [21] is a system that uses distributed lockservers.  Boxwood provides higher-level abstractions toapplications, and it relies upon a distributed lock servicebased on Paxos.  Like Boxwood,  ZooKeeper is a com-ponent  used  to  build  distributed  systems.   ZooKeeper,however, has high-performance requirements and is usedmore extensively in client applications.  ZooKeeper ex-poses lower-level primitives that applications use to im-plement higher-level primitives.

ZooKeeper resembles a small file system, but it onlyprovides  a  small  subset  of  the  file  system  operationsand adds functionality not present in most file systemssuch as ordering guarantees and conditional writes. Zoo-Keeper  watches,  however,  are  similar  in  spirit  to  thecache callbacks of AFS [16].

Sinfonia   [2]   introducesmini-transactions,   a   newparadigm for building scalable distributed systems.  Sin-fonia   has   been   designed   to   store   application   data,whereas  ZooKeeper  stores  application  metadata.   Zoo-Keeper keeps its state fully replicated and in memory forhigh performance and consistent latency. Our use of filesystem like operations and ordering enables functionalitysimilar to mini-transactions.  The znode is a convenientabstraction upon which we add watches, a functionalitymissing in Sinfonia.  Dynamo [11] allows clients to getand put relatively small (less than 1M) amounts of data ina distributed key-value store. Unlike ZooKeeper, the keyspace in Dynamo is not hierarchal.  Dynamo also doesnot provide strong durability and consistency guaranteesfor writes, but instead resolves conflicts on reads.

DepSpace [4] uses a tuple space to provide a Byzan-tine  fault-tolerant  service.   Like  ZooKeeper  DepSpaceuses a simple server interface to implement strong syn-chronization primitives at the client.  While DepSpace’sperformance is much lower than ZooKeeper, it providesstronger fault tolerance and confidentiality guarantees.

7 Conclusions
ZooKeeper takes a wait-free approach to the problem ofcoordinating processes in distributed systems, by expos-ing  wait-free  objects  to  clients.   We  have  found  Zoo-Keeper to be useful for several applications inside andoutside  Yahoo!.    ZooKeeper  achieves  throughput  val-ues of hundreds of thousands of operations per secondfor  read-dominant  workloads  by  using  fast  reads  withwatches,  both  of  which  served  by  local  replicas.   Al-though our consistency guarantees for reads and watchesappear to be weak, we have shown with our use cases thatthis  combination  allows  us  to  implement  efficient  andsophisticated  coordination  protocols  at  the  client  eventhough reads are not precedence-ordered and the imple-mentation  of  data  objects  is  wait-free.    The  wait-freeproperty has proved to be essential for high performance.

Although we have described only a few applications,there are many others using ZooKeeper. We believe sucha success is due to its simple interface and the powerfulabstractions that one can implement through this inter-face.   Further,  because  of  the  high-throughput  of  Zoo-Keeper,  applications  can  make  extensive  use  of  it,  notonly course-grained locking.
