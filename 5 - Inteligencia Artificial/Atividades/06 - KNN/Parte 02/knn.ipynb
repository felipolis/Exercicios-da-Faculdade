{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINA AQUI A CONFIGURAÇÃO DO SEU MODELO\n",
    "# ----------------------------------------\n",
    "# Número de vizinhos\n",
    "k = 3\n",
    "# Porcentagem de dados para treino (1, 0.5, 0.25)\n",
    "porcentagem = 1\n",
    "# Normalização (minmax ou zscore)\n",
    "normalizacao = 'minmax'\n",
    "# Distância (euclideana ou manhattan)\n",
    "distancia = 'manhattan'\n",
    "# PATH dos arquivos:\n",
    "path_treino = './data/treino_1x1.csv'\n",
    "path_teste = './data/teste_1x1.csv'\n",
    "# ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a distância euclidiana entre dois pontos\n",
    "def distancia_euclidiana(ponto1, ponto2):\n",
    "    dim, soma = len(ponto1), 0\n",
    "    for i in range(dim):\n",
    "        soma += math.pow(ponto1[i] - ponto2[i], 2)\n",
    "    return math.sqrt(soma)\n",
    "\n",
    "# Função para calcular a distância de Manhattan entre dois pontos\n",
    "def distancia_manhattan(ponto1, ponto2):\n",
    "    dim, soma = len(ponto1), 0\n",
    "    for i in range(dim):\n",
    "        soma += abs(ponto1[i] - ponto2[i])\n",
    "    return soma\n",
    "\n",
    "def minmax_normalization(samples):\n",
    "    \"\"\"\n",
    "    Aplica normalização Min-Max em cada coluna do array de amostras.\n",
    "    \n",
    "    Args:\n",
    "    samples (numpy.ndarray): Array de amostras a ser normalizado\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Array de amostras normalizado\n",
    "    \"\"\"\n",
    "    # Calcula os valores mínimo e máximo de cada coluna\n",
    "    min_vals = np.min(samples, axis=0)\n",
    "    max_vals = np.max(samples, axis=0)\n",
    "    \n",
    "    # Calcula o intervalo de cada coluna\n",
    "    ranges = max_vals - min_vals\n",
    "    \n",
    "    # Aplica a fórmula de normalização Min-Max em cada coluna\n",
    "    normalized_samples = (samples - min_vals) / ranges\n",
    "    \n",
    "    return normalized_samples\n",
    "\n",
    "def zscore_normalization(samples):\n",
    "    \"\"\"\n",
    "    Aplica normalização Z-score em cada coluna do array de amostras.\n",
    "    \n",
    "    Args:\n",
    "    samples (numpy.ndarray): Array de amostras a ser normalizado\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Array de amostras normalizado\n",
    "    \"\"\"\n",
    "    # Calcula a média e o desvio padrão de cada coluna\n",
    "    means = np.mean(samples, axis=0)\n",
    "    stds = np.std(samples, axis=0)\n",
    "    \n",
    "    # Aplica a fórmula de normalização Z-score em cada coluna\n",
    "    normalized_samples = (samples - means) / stds\n",
    "    \n",
    "    return normalized_samples\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def treinar(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def prever(self, ponto):\n",
    "        distancias = {}\n",
    "        for i in range(len(self.X)):\n",
    "            if distancia == 'euclidiana':\n",
    "                d = distancia_euclidiana(self.X[i], ponto)\n",
    "            else:\n",
    "                d = distancia_manhattan(self.X[i], ponto)\n",
    "            distancias[i] = d\n",
    "        # Ordenar as distâncias do menor para o maior e obter os índices correspondentes\n",
    "        indices = sorted(distancias, key=distancias.get)[:self.k]\n",
    "        # Obter as classes dos k vizinhos mais próximos\n",
    "        classes = [self.y[i] for i in indices]\n",
    "        # Retornar a classe mais frequente\n",
    "        return max(set(classes), key=classes.count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados de treinamento\n",
    "df_treino = pd.read_csv(path_treino)\n",
    "y_treino = df_treino['classe'].values\n",
    "X_treino = df_treino.drop('classe', axis=1).values\n",
    "\n",
    "# Carregar os dados de teste\n",
    "df_teste = pd.read_csv(path_teste)\n",
    "y_teste = df_teste['classe'].values\n",
    "X_teste = df_teste.drop('classe', axis=1).values\n",
    "\n",
    "# Normalizar os dados de treinamento e teste\n",
    "if normalizacao == 'minmax':\n",
    "    X_treino = minmax_normalization(X_treino)\n",
    "    X_teste = minmax_normalization(X_teste)\n",
    "else:\n",
    "    X_treino = zscore_normalization(X_treino)\n",
    "    X_teste = zscore_normalization(X_teste)\n",
    "\n",
    "# Selecionar uma amostra aleatória dos dados de treinamento\n",
    "n = int(porcentagem * len(X_treino))\n",
    "indices = random.sample(range(len(X_treino)), n)\n",
    "X_treino = [X_treino[i] for i in indices]\n",
    "y_treino = [y_treino[i] for i in indices]\n",
    "\n",
    "# Treinar o modelo\n",
    "modelo = KNN(k)\n",
    "modelo.treinar(X_treino, y_treino)\n",
    "\n",
    "# Testar o modelo\n",
    "y_pred = [modelo.prever(ponto) for ponto in X_teste]\n",
    "\n",
    "# Calcular a acurácia\n",
    "acuracia = sum(y_pred == y_teste) / len(y_teste)\n",
    "print('Acurácia: {:.2f}%'.format(acuracia * 100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
